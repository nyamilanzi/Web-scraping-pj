{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "def scrape_job_description(url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        job_description_elem = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"job_description\"))\n",
    "        )\n",
    "        job_description = job_description_elem.text.strip()\n",
    "    except:\n",
    "        job_description = None\n",
    "    return job_description\n",
    "\n",
    "\n",
    "def scrape_listings(page_source, processed_links):\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    job_listings = soup.find_all('li', class_='job_listing')\n",
    "    listings_data = []\n",
    "    for listing in job_listings:\n",
    "        job_position_elem = listing.find('h3')\n",
    "        job_position = job_position_elem.text.strip() if job_position_elem else None\n",
    "        if job_position == \"How to Search For a Job Advert\" or job_position == \"Copycats of Our Site  (Dont Support Laziness)\":\n",
    "            continue\n",
    "        \n",
    "        company_elem = listing.find('div', class_='company')\n",
    "        company = company_elem.strong.text.strip() if company_elem and company_elem.strong else None\n",
    "        if company is None:\n",
    "            continue\n",
    "\n",
    "        location_elem = listing.find('div', class_='location')\n",
    "        location = location_elem.text.strip() if location_elem else None\n",
    "        if location is None:\n",
    "            continue\n",
    "\n",
    "        job_type_elem = listing.find('li', class_='job-type')\n",
    "        job_type = job_type_elem.text.strip() if job_type_elem else None\n",
    "        if job_type is None:\n",
    "            continue\n",
    "\n",
    "        posting_date_elem = listing.find('li', class_='date')\n",
    "        posting_date = posting_date_elem.time['datetime'] if posting_date_elem else None\n",
    "        if posting_date is None:\n",
    "            continue\n",
    "\n",
    "        job_link_elem = listing.find('a', href=True)\n",
    "        job_link = job_link_elem['href'] if job_link_elem else None\n",
    "\n",
    "        if job_link not in processed_links:\n",
    "            listing_data = {\n",
    "                'Position': job_position,\n",
    "                'Company': company,\n",
    "                'Location': location,\n",
    "                'Job Type': job_type,\n",
    "                'Posting Date': posting_date,\n",
    "                'Job Link': job_link\n",
    "            }\n",
    "            listings_data.append(listing_data)\n",
    "            processed_links.add(job_link)\n",
    "    return listings_data\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://jobsearchmalawi.com/\")\n",
    "\n",
    "\n",
    "start_date = datetime.datetime(2024, 3, 1)\n",
    "\n",
    "\n",
    "end_date = datetime.datetime(2024, 5, 13)\n",
    "\n",
    "new_listings = []\n",
    "processed_links = set()\n",
    "\n",
    "while True:  \n",
    "    try:\n",
    "        load_more_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"load_more_jobs\"))\n",
    "        )\n",
    "        load_more_button.click()\n",
    "        time.sleep(2)  \n",
    "        page_source = driver.page_source\n",
    "        scraped_listings = scrape_listings(page_source, processed_links)\n",
    "        \n",
    "        if not scraped_listings:\n",
    "            print(\"No more listings found.\")\n",
    "            break\n",
    "        \n",
    "        for listing in scraped_listings:\n",
    "            posting_date = datetime.datetime.strptime(listing['Posting Date'], \"%Y-%m-%d\")\n",
    "            if posting_date > end_date:\n",
    "                continue\n",
    "            if posting_date < start_date:\n",
    "                print(\"Reached the specified timeframe.\")\n",
    "                break\n",
    "            new_listings.append(listing)\n",
    "        \n",
    "        print(\"Processed links:\", processed_links) \n",
    "        print(\"Total listings:\", len(new_listings))  \n",
    "\n",
    "        \n",
    "        if posting_date < start_date:\n",
    "            print(\"Reached the specified timeframe.\")\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        break  \n",
    "\n",
    "if new_listings:\n",
    "    df = pd.DataFrame(new_listings)\n",
    "    df.to_csv('jobsearch_listings.csv', index=False)\n",
    "    \n",
    "    descriptions = []\n",
    "    for job_link in df['Job Link']:  \n",
    "        description = scrape_job_description(job_link)\n",
    "        descriptions.append(description)\n",
    "    \n",
    "    df['Job Description'] = descriptions\n",
    "   \n",
    "    df.to_csv('jobsearch_listings_with_descriptions.csv', index=False)\n",
    "    print(\"Job descriptions scraped successfully.\")\n",
    "else:\n",
    "    print(\"No new listings found.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
